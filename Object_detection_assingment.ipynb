{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "6442da43-01f9-4e5b-85d6-ac14823bb9d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import ultralytics "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "23accd31-6f6e-4825-bf67-210de058d924",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import math\n",
    "import numpy as np\n",
    "import cvzone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "a0aaf84d-6178-44f6-98af-a3e4f65cfb42",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=YOLO(\"C:/Users/HP/Desktop/Yolo-Weights/yolov8n.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "9a0d5bdb-c7d3-4723-871e-76cc534c955c",
   "metadata": {},
   "outputs": [],
   "source": [
    "classNames = [\n",
    "    \"person\", \"bicycle\", \"car\", \"motorbike\", \"aeroplane\", \"bus\", \"train\", \"truck\", \"boat\",\n",
    "    \"traffic light\", \"fire hydrant\", \"stop sign\", \"parking meter\", \"bench\", \"bird\", \"cat\", \n",
    "    \"dog\", \"horse\", \"sheep\", \"cow\", \"elephant\", \"bear\", \"zebra\", \"giraffe\", \"backpack\", \"umbrella\", \n",
    "    \"handbag\", \"tie\", \"suitcase\", \"frisbee\", \"skis\", \"snowboard\", \"sports ball\", \"kite\", \n",
    "    \"baseball bat\", \"baseball glove\", \"skateboard\", \"surfboard\", \"tennis racket\", \"bottle\", \n",
    "    \"wine glass\", \"cup\", \"fork\", \"knife\", \"spoon\", \"bowl\", \"banana\", \"apple\", \"sandwich\", \"orange\", \n",
    "    \"broccoli\", \"carrot\", \"hot dog\", \"pizza\", \"donut\", \"cake\", \"chair\", \"sofa\", \"potted plant\", \n",
    "    \"bed\", \"dining table\", \"toilet\", \"tv monitor\", \"laptop\", \"mouse\", \"remote\", \"keyboard\", \"cell phone\", \n",
    "    \"microwave\", \"oven\", \"toaster\", \"sink\", \"refrigerator\", \"book\", \"clock\", \"vase\", \"scissors\", \n",
    "    \"teddy bear\", \"hair dryer\", \"toothbrush\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "2b1af1a8-7b41-48f1-925e-884ed793929c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap=cv2.VideoCapture(\"C:/Users/HP/Downloads/2103099-uhd_3840_2160_30fps.mp4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "a52e380a-3431-4950-9d3a-dc7540e06e12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3840 2160\n"
     ]
    }
   ],
   "source": [
    "scale=0.3\n",
    "width=int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height=int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "print(width,height)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "b6983ae3-7f2f-4742-867b-e161150c1f1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 20 cars, 1 bus, 2 trucks, 52.8ms\n",
      "Speed: 3.9ms preprocess, 52.8ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 20 cars, 1 bus, 2 trucks, 73.0ms\n",
      "Speed: 2.0ms preprocess, 73.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 22 cars, 1 bus, 2 trucks, 52.8ms\n",
      "Speed: 2.8ms preprocess, 52.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 22 cars, 1 bus, 2 trucks, 53.0ms\n",
      "Speed: 2.0ms preprocess, 53.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 23 cars, 1 bus, 2 trucks, 50.9ms\n",
      "Speed: 2.0ms preprocess, 50.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 22 cars, 1 bus, 2 trucks, 53.8ms\n",
      "Speed: 3.0ms preprocess, 53.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 23 cars, 1 bus, 3 trucks, 50.0ms\n",
      "Speed: 2.0ms preprocess, 50.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 24 cars, 1 bus, 2 trucks, 52.5ms\n",
      "Speed: 3.0ms preprocess, 52.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 23 cars, 1 bus, 2 trucks, 52.6ms\n",
      "Speed: 2.0ms preprocess, 52.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 23 cars, 1 bus, 2 trucks, 49.9ms\n",
      "Speed: 2.5ms preprocess, 49.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 23 cars, 1 bus, 1 truck, 48.9ms\n",
      "Speed: 2.9ms preprocess, 48.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 21 cars, 2 buss, 1 truck, 46.8ms\n",
      "Speed: 2.0ms preprocess, 46.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 24 cars, 2 buss, 1 truck, 53.3ms\n",
      "Speed: 2.7ms preprocess, 53.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 22 cars, 2 buss, 1 truck, 51.5ms\n",
      "Speed: 2.0ms preprocess, 51.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 23 cars, 1 bus, 1 truck, 47.9ms\n",
      "Speed: 2.1ms preprocess, 47.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 22 cars, 1 bus, 1 truck, 48.9ms\n",
      "Speed: 2.9ms preprocess, 48.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 19 cars, 1 bus, 1 truck, 61.6ms\n",
      "Speed: 3.4ms preprocess, 61.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 21 cars, 1 bus, 1 truck, 78.5ms\n",
      "Speed: 3.0ms preprocess, 78.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 22 cars, 1 bus, 1 truck, 69.2ms\n",
      "Speed: 3.0ms preprocess, 69.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 21 cars, 1 bus, 1 truck, 69.3ms\n",
      "Speed: 3.0ms preprocess, 69.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 19 cars, 1 bus, 2 trucks, 57.9ms\n",
      "Speed: 4.2ms preprocess, 57.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 21 cars, 1 bus, 2 trucks, 69.9ms\n",
      "Speed: 3.0ms preprocess, 69.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 23 cars, 1 bus, 1 truck, 64.1ms\n",
      "Speed: 4.0ms preprocess, 64.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 21 cars, 2 buss, 1 truck, 62.6ms\n",
      "Speed: 2.4ms preprocess, 62.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 22 cars, 3 buss, 1 truck, 71.5ms\n",
      "Speed: 3.2ms preprocess, 71.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 25 cars, 2 buss, 1 truck, 70.8ms\n",
      "Speed: 3.0ms preprocess, 70.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 19 cars, 2 buss, 1 truck, 66.2ms\n",
      "Speed: 2.0ms preprocess, 66.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 22 cars, 1 bus, 1 truck, 66.9ms\n",
      "Speed: 3.4ms preprocess, 66.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 21 cars, 1 bus, 1 truck, 67.8ms\n",
      "Speed: 4.2ms preprocess, 67.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 18 cars, 1 bus, 1 truck, 67.5ms\n",
      "Speed: 3.0ms preprocess, 67.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 19 cars, 1 bus, 1 truck, 59.2ms\n",
      "Speed: 3.5ms preprocess, 59.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 20 cars, 1 bus, 2 trucks, 59.3ms\n",
      "Speed: 3.5ms preprocess, 59.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 18 cars, 2 buss, 1 truck, 79.2ms\n",
      "Speed: 2.0ms preprocess, 79.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 19 cars, 1 bus, 1 truck, 67.3ms\n",
      "Speed: 4.2ms preprocess, 67.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 18 cars, 1 bus, 1 truck, 74.3ms\n",
      "Speed: 3.5ms preprocess, 74.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 18 cars, 1 bus, 2 trucks, 80.8ms\n",
      "Speed: 2.7ms preprocess, 80.8ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 20 cars, 1 bus, 2 trucks, 71.3ms\n",
      "Speed: 3.8ms preprocess, 71.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 22 cars, 1 bus, 2 trucks, 57.6ms\n",
      "Speed: 3.3ms preprocess, 57.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 22 cars, 1 bus, 3 trucks, 64.3ms\n",
      "Speed: 3.8ms preprocess, 64.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 18 cars, 1 bus, 1 truck, 57.2ms\n",
      "Speed: 2.5ms preprocess, 57.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 19 cars, 1 bus, 2 trucks, 54.7ms\n",
      "Speed: 3.7ms preprocess, 54.7ms inference, 14.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 19 cars, 1 bus, 1 truck, 78.4ms\n",
      "Speed: 4.5ms preprocess, 78.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 18 cars, 1 bus, 2 trucks, 55.9ms\n",
      "Speed: 4.0ms preprocess, 55.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    ret,frame=cap.read()\n",
    "    frame=cv2.resize(frame,(int(width*scale),int(height*scale)))\n",
    "    result=model(frame,stream=True)\n",
    "    detection=np.empty((0,5))\n",
    "    for r in result:\n",
    "        boxes=r.boxes\n",
    "        for box in boxes:\n",
    "            x1,y1,x2,y2=box.xyxy[0]\n",
    "            x1,y1,x2,y2=int(x1),int(y1),int(x2),int(y2)\n",
    "            conf=math.ceil((box.conf[0]*100))/100\n",
    "            cls=int(box.cls[0])\n",
    "            if conf>0.4:\n",
    "                currentArray=np.array([x1,y1,x2,y2,conf])\n",
    "                detections=np.vstack((detection,currentArray))\n",
    "                cvzone.cornerRect(frame,(x1,y1,x2-x1,y2-y1),l=9,rt=4,colorR=(255,0,0))\n",
    "                className=classNames[cls]\n",
    "                cvzone.putTextRect(frame,f\"{conf} {className}\",(max(0, x1), max(35, y1)),scale=0.7,thickness=1)\n",
    "            \n",
    "    cv2.imshow('img',frame)\n",
    "    \n",
    "    if cv2.waitKey(1) & 0xFF==ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b392ae9f-a54e-4e31-8e0b-7da6f5f16bc9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
